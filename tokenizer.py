# -*- coding: utf-8 -*-
"""tokenizer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HgoTx8-FChxev8DY_qyrbToDovT6TOiv
"""

# tokenizer.py

class CharTokenizer:
    def __init__(self, text_file):
        with open(text_file, 'r', encoding='utf-8') as f:
            text = f.read()
        self.chars = sorted(list(set(text)))
        self.char_to_id = {ch: i for i, ch in enumerate(self.chars)}
        self.id_to_char = {i: ch for ch, i in self.char_to_id.items()}

    def encode(self, text):
        return [self.char_to_id.get(ch, 0) for ch in text]

    def decode(self, ids):
        return ''.join([self.id_to_char.get(i, '?') for i in ids])

    def vocab_size(self):
        return len(self.chars)