# -*- coding: utf-8 -*-
"""test_encoding_bpe.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yBQ4siGjfQ4eXEMxwfIC7xSxAuEJZsAF
"""

from tokenizers import Tokenizer

# Load the trained tokenizer
tokenizer = Tokenizer.from_file("bpe_tokenizer.json")

# Sample sentences (multilingual)
samples = [
    "How are you?",
    "Yela unnav?",
    "Eppadi irukkeenga?",
    "Kya haal hai?"
]

# Encode and show token IDs
for sentence in samples:
    encoded = tokenizer.encode(sentence)
    print(f"Input: {sentence}")
    print(f"Tokens: {encoded.tokens}")
    print(f"IDs: {encoded.ids}")
    print("-----")